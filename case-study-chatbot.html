<html>

<head>
    <link href="css/page.css" rel="stylesheet" type="text/css" />
</head>

<body>

    <h1>Chatbot usability evaluation</h1>
    <h2>Problem Statement</h2>
    <p>The client was designing a new chatbot feature on their teaching platform to help users (primarily teachers) find
        information they were looking for more efficiently.</p>
    <p>Key Research Questions:</p>
    <ol>
        <li>Did users notice the new chatbot?</li>
        <li>Given that the users know about the chatbot, would the users choose to use it?</li>
        <li>When using the chatbot, were the users able to find the relevant information or be guided toward the correct
            part of the website?</li>
    </ol>
    <h2>Methodology</h2>
    <p>Since this was performed during the COVID-19 pandemic, there was a requirement for all testing to be performed
        remotely, within a timeframe of 6 weeks.<br>
        Methods used:</p>
    <ul>
        <li>Moderated remote usability study</li>
        <li>Email surveys</li>
    </ul>
    <h2>Recruitment</h2>
    <p>The platform was primarily available to teachers and department heads. Due to this, the client already had
        preselected a series of potential candidates,
        half of whom had experience using the platform (without the new functionality), and the other half had no
        experience of the platform prior to evaluation.</p>

    <h2>Moderated Remote Usability Study</h2>
    <p>Due to the COVID-19 pandemic, the evaluation needed to be performed remotely, being recorded over Zoom. In all
        parts of the usability study users were provided tasks to find information while following a think out loud
        protocol. They were prompted for their thoughts and attitude several times throughout and after the tasks.<br>
        Firstly, users were asked open-ended questions to find information that would help their head of department
        understand why there had been a recent dip in overall student performance. The platform contained a large amount
        of data that was open to interpretation.<br>
        For the second part of the study, users were first informed about the existence of the chatbot. Users were again
        asked to find additional information related to something more specific, and were again reminded about the
        chatbot prior to starting.<br>
        In the final part of the study, users were instructed to specifically use the chatbot to find the last pieces of
        information.<br>
    </p>

    <h2>Survey</h2>
    <p>After the usability study, participants were emailed surveys to gather demographic data, including prior website
        usage. The survey was also used to identify discrepancies from the study, clarify trends, and gain any
        additional thoughts they may have only had after finishing the tasks.</p>

    <h2>Data Analysis</h2>
    <p>
        Interviews were transcribed, and then analyzed to determine several dimensions along with the survey
        responses.<br>
        For each dimension, data was collated for metrics, such as shown in the below table.<br>

    <table>
        <tr>
            <th>Dimension</th>
            <th>Positive remarks</th>
            <th>Neutral remarks</th>
            <th>Negative remarks</th>
        </tr>
        <tr>
            <th>Chatbot satisfaction</th>
            <th>2</th>
            <th>1</th>
            <th>3</th>
        </tr>
        <tr>
            <th>Chatbot functionality</th>
            <th>4</th>
            <th>0</th>
            <th>2</th>
        </tr>
    </table>



    From the survey data we were able to confirm the categorization of "expert" and "novice" users based on their prior
    experience of the platform, which helped us further evaluate the differences in responses across these groups.

    </p>

    <h2>Key Findings</h2>
    <ul>
        <li>Users were generally unaware of the chatbot unless initially directed toward it.</li>
        <li>Novice users were more likely to use the chatbot, and found it more useful.</li>
        <li>Expert users of the platform were more likely to be frustrated with the chatbot and be hindered by being
            forced into use.</li>
        <li>Specific areas of frustration and confusion with chatbot functionality were identified with recommendations
            based on stated expected outcomes.</li>
    </ul>


    <h2>What if I had the chance to do it again?</h2>
    <p>If I had a chance to perform this evaluation again, I would like to spend more time focused on the chatbot
        itself, giving participants more scenarios in which they had to use the chatbot. The chatbot functionality was
        also only compared to the absence of a chatbot, whereas I think it would be useful to also have a comparison to
        other functionality such as a search bar. For methodology, I would add clickstream analysis by having a piece of
        software collect this data, though this would be easier if the evaluation could have been in-person. This
        evaluation only counted page navigation as a rudimentary metric. </p>
</body>

</html>