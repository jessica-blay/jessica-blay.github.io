<html>

<head>
    <link href="css/page.css" rel="stylesheet" type="text/css" />
</head>

<body>

    <h1>Dashboard Focus group</h1>
    <h2>Problem Statement</h2>
    <p>
        The client was developing a personalized dashboard for university professors to show them performance in their
        classes along with information about their student body. The data included was not fake data, not personalized
        for the users of the focus group, but participants were asked to act as if it were.<br>
        Key Research Questions:<br>
    <ol>
        <li>What were users' reactions and behavior to the data being provided to them?</li>
        <li>What was a professor's reaction to seeing negative results from their teaching?</li>
        <li>Can users understand the way the data is presented such that it could be used to improve teaching?</li>
    </ol>
    <h2>Methodology</h2>
    <p>This was performed during the COVID-19 pandemic, and therefore there was a requirement for all testing to be
        performed
        remotely. Due to the busy schedule of university professors, sessions could not last longer than 60 minutes.
        <br>
        In this evaluation we opted for a series of focus groups with a walkthrough analysis of a prototype of the
        website. After the focus group, participants were also emailed a survey for demographic data and to include
        additional information in case they wished not to disagree with others in person.
    </p>

    <h2>Recruitment</h2>
    <p>
        The personalized dashboard was being designed for a series of universities, and was intended to be viewed by
        professors and department heads to review data. Therefore recruitment was limited to current (or recently
        retired) professors that were (or had been) working within the associated group of universities. As a professor
        himself, our supervisor reached out to colleagues within those universities to gather participants for the
        study. <br>
    </p>

    <h2>Challenges and Solutions</h2>
    <h3>Challenge: Schedules</h3>
    <p>Due to professors' busy schedules we were only able to have focus groups lasting 60 minutes. As such we had to be
        very careful with our question selection. Several dry-runs of the questions were performed with colleagues to
        make the questions less vague, prevent straying topic, and questions were combined where possible, or ommitted
        when less relevant. Due to the busy schedules it was also difficult to get a day where all participants were
        available at the same time, therefore we ended up having a series of focus smaller focus groups.</p>
    <h3>Challenge: Remote Focus Groups</h3>
    <p>We identified several potential problems that may arise from remote focus groups along with solutions. For
        example:</p>

    <table>
        <tr>
            <th>Problem</th>
            <th>Solution</th>
        </tr>
        <tr>
            <th>Distractions</th>
            <th>Close all other computer applications, and enable "do not disturb" functionality if applicable.<br>Turn
                off cell phones.</th>
        </tr>
        <tr>
            <th>Mic/Speaker/Camera problems</th>
            <th>Try to get everyone on the call early to confirm no problems. 2 interviewers were available so that 1
                could take over if technological problems with the other.</th>
        </tr>
        <tr>
            <th>Ease of interruptions</th>
            <th>Remote meetings make it very possible to easily talk over each other. We tried to have each person speak
                one at a time and use "hand raise" features available.</th>
        </tr>
        <tr>
            <th>Straying answers</th>
            <th>Prompts created to keep participants focused on the question at hand. Where possible, questions were
                re-worded to prevent straying.</th>
        </tr>
    </table>


    <h2>Data Analysis</h2>
    <p>
        Focus groups were transcribed, and then analyzed to determine several dimensions along with the survey
        responses.<br>
        Dimensions such as "Interface" and "Clarity" were identified, and comments were grouped together as either
        positive, negative, or neutral comments within these dimensions.<br>
        Areas of agreements and disagreements between participants within the focus groups were also identified in case
        they affected other results.
    </p>

    <h2>Key Findings</h2>
    <p>We identified that although participants may be surprised by negative results, this was generally taken as an
        area of potential improvement and that participants wanted to derive information that could be used to improve
        their results over time. However, there was a concern that this could be used as an evaluation tool when there
        may be other circumstances not considered in this dataset.<br>
        On the other hand, all participants had problems with the data as being insufficient in specific areas.
        Professors coming from more scientific backgrounds in particular wanted to look at the raw data to determine if
        they could try to interpret other information from it, which was not included.</p>

    <h2>Outcomes</h2>
    <ul>
        <li>Actionable insights were added to pages to make it clearer how this data could be used to improve in the
            future.</li>
        <li>Specific data deficiencies were resolved prior to going live that made those graphs and datasets more useful
            to professors.</li>
        <li>The platform was able to show how raw data could be obtained.</li>
    </ul>

    <h2>What if I had the chance to do it again?</h2>
    <p>If I had the opportunity again, I would like to have performed this focus group in person. Multiple people
        interacting together in a room provides additional insights and body language changes that may not have been
        evident remotely. If a prototype of the website was generally made available so that participants could have
        used the website themselves, this may have provided more insights into potential areas of improvement as
        well.<br>
        I think it is also difficult to accurately act as if negative data is being displayed about your performance.
        Some participants had difficulty relating to the data provided (for example, class sizes were too big, or
        demographic information was very different from their typical classes), which meant their reactions to bad data
        were likely harder to fake, with the data being so far from their reality. A more accurate representation of
        emotion may be possible if participants were actually looking at their personalized data, but it had been
        modified to show more negative results than reality.<br>
    </p>
</body>

</html>